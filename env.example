# Required: Groq API key (free tier available at https://console.groq.com)
GROQ_API_KEY=your_groq_api_key_here

# LLM Model Configuration
GROQ_MODEL_ORCH=llama-3.1-8b-instant
GROQ_MODEL_WRITER=llama-3.1-70b-versatile

# Embedding Configuration
EMBED_BACKEND=fastembed
EMBED_MODEL_NAME=BAAI/bge-small-en-v1.5

# Optional: Tavily Search API
TAVILY_API_KEY=

# Optional: LangSmith tracing
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=research-to-blog

# Publishing Configuration
PUBLISH_TARGET=dryrun

# Quality Gates
MIN_CITATION_COVERAGE=0.95
MAX_UNSUPPORTED_CLAIMS=0.05
MIN_FACT_CONFIDENCE=0.7
TARGET_READING_LEVEL=60

# Rate Limiting
MAX_GROQ_RPM=30
MAX_GROQ_TOKENS_PER_MIN=14000
MAX_PIPELINE_TIME_SECONDS=600
MAX_PIPELINE_TOKENS=100000

# Data Storage
CHROMA_PERSIST_DIR=./data/chroma
CACHE_DIR=./data/cache
OUTPUT_DIR=./outputs

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

